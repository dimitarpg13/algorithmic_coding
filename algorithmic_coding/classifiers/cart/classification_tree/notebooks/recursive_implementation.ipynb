{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Recursive Classification Tree (CART) - Testing & Visualization\n",
        "\n",
        "This notebook demonstrates and tests the recursive implementation of a Classification and Regression Tree (CART) for classification tasks.\n",
        "\n",
        "## Contents\n",
        "1. **Setup & Imports**\n",
        "2. **Basic Classification Tests**\n",
        "3. **Decision Boundary Visualization**\n",
        "4. **Multiclass Classification**\n",
        "5. **Hyperparameter Tuning Analysis**\n",
        "6. **Comparison with scikit-learn**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "# Add parent directories to path for imports\n",
        "sys.path.insert(0, '../../../../..')\n",
        "\n",
        "from algorithmic_coding.classifiers.cart.classification_tree.recursive_implementation import ClassificationTree\n",
        "\n",
        "# Set style for plots\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (10, 6)\n",
        "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
        "\n",
        "# Color palettes\n",
        "COLORS_LIGHT = ['#FFB3BA', '#BAFFC9', '#BAE1FF', '#FFFFBA']\n",
        "COLORS_DARK = ['#E74C3C', '#27AE60', '#3498DB', '#F39C12']\n",
        "\n",
        "print(\"âœ“ Setup complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 1. Basic Classification Tests\n",
        "\n",
        "Let's start with simple tests to verify the classifier works correctly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test 1: Simple linearly separable data\n",
        "print(\"Test 1: Linearly Separable Binary Classification\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "X_simple = np.array([\n",
        "    [1, 2], [2, 3], [3, 1], [4, 2],  # Class 0\n",
        "    [6, 7], [7, 8], [8, 6], [9, 7]   # Class 1\n",
        "])\n",
        "y_simple = np.array([0, 0, 0, 0, 1, 1, 1, 1])\n",
        "\n",
        "clf = ClassificationTree(max_depth=5)\n",
        "clf.fit(X_simple, y_simple)\n",
        "\n",
        "print(f\"Training accuracy: {clf.score(X_simple, y_simple):.2%}\")\n",
        "print(f\"Tree depth: {clf.get_depth()}\")\n",
        "print(f\"Number of leaves: {clf.get_n_leaves()}\")\n",
        "print(f\"\\nPredictions: {clf.predict(X_simple)}\")\n",
        "print(f\"True labels: {y_simple}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test 2: Probability predictions\n",
        "print(\"\\nTest 2: Probability Predictions\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "proba = clf.predict_proba(X_simple)\n",
        "print(\"Class probabilities (first 4 samples):\")\n",
        "print(f\"  Sample 0: P(class=0)={proba[0, 0]:.2f}, P(class=1)={proba[0, 1]:.2f}\")\n",
        "print(f\"  Sample 4: P(class=0)={proba[4, 0]:.2f}, P(class=1)={proba[4, 1]:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 2. Decision Boundary Visualization\n",
        "\n",
        "Visualize how the tree partitions the feature space.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_decision_boundary(clf, X, y, title=\"Decision Boundary\", ax=None):\n",
        "    \"\"\"\n",
        "    Plot the decision boundary of a classifier along with training data.\n",
        "    \"\"\"\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots(figsize=(10, 8))\n",
        "    \n",
        "    # Create mesh grid\n",
        "    h = 0.02  # Step size\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                         np.arange(y_min, y_max, h))\n",
        "    \n",
        "    # Predict on mesh\n",
        "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    \n",
        "    # Get number of classes\n",
        "    n_classes = len(np.unique(y))\n",
        "    cmap_light = ListedColormap(COLORS_LIGHT[:n_classes])\n",
        "    cmap_dark = ListedColormap(COLORS_DARK[:n_classes])\n",
        "    \n",
        "    # Plot decision regions\n",
        "    ax.contourf(xx, yy, Z, alpha=0.4, cmap=cmap_light)\n",
        "    ax.contour(xx, yy, Z, colors='gray', linewidths=0.5, alpha=0.5)\n",
        "    \n",
        "    # Plot training points\n",
        "    scatter = ax.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_dark, \n",
        "                         edgecolors='white', s=100, linewidths=1.5)\n",
        "    \n",
        "    ax.set_xlabel('Feature 1', fontsize=12)\n",
        "    ax.set_ylabel('Feature 2', fontsize=12)\n",
        "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
        "    \n",
        "    return ax\n",
        "\n",
        "# Visualize simple classification\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "plot_decision_boundary(clf, X_simple, y_simple, \n",
        "                      title=\"Decision Boundary - Simple Binary Classification\", ax=ax)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Gaussian Clusters Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate Gaussian clusters\n",
        "np.random.seed(42)\n",
        "\n",
        "n_samples = 100\n",
        "mean_0 = [2, 2]\n",
        "mean_1 = [6, 6]\n",
        "cov = [[1, 0.5], [0.5, 1]]\n",
        "\n",
        "X_0 = np.random.multivariate_normal(mean_0, cov, n_samples)\n",
        "X_1 = np.random.multivariate_normal(mean_1, cov, n_samples)\n",
        "\n",
        "X_gauss = np.vstack([X_0, X_1])\n",
        "y_gauss = np.array([0] * n_samples + [1] * n_samples)\n",
        "\n",
        "# Shuffle data\n",
        "shuffle_idx = np.random.permutation(len(y_gauss))\n",
        "X_gauss = X_gauss[shuffle_idx]\n",
        "y_gauss = y_gauss[shuffle_idx]\n",
        "\n",
        "# Split train/test\n",
        "split = int(0.8 * len(y_gauss))\n",
        "X_train, X_test = X_gauss[:split], X_gauss[split:]\n",
        "y_train, y_test = y_gauss[:split], y_gauss[split:]\n",
        "\n",
        "# Fit classifier\n",
        "clf_gauss = ClassificationTree(max_depth=5)\n",
        "clf_gauss.fit(X_train, y_train)\n",
        "\n",
        "print(\"Gaussian Clusters Dataset\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Training samples: {len(X_train)}\")\n",
        "print(f\"Test samples: {len(X_test)}\")\n",
        "print(f\"Training accuracy: {clf_gauss.score(X_train, y_train):.2%}\")\n",
        "print(f\"Test accuracy: {clf_gauss.score(X_test, y_test):.2%}\")\n",
        "print(f\"Tree depth: {clf_gauss.get_depth()}\")\n",
        "print(f\"Number of leaves: {clf_gauss.get_n_leaves()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize Gaussian clusters with decision boundary\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Training data\n",
        "plot_decision_boundary(clf_gauss, X_train, y_train, \n",
        "                      title=\"Training Data & Decision Boundary\", ax=axes[0])\n",
        "\n",
        "# Test data\n",
        "plot_decision_boundary(clf_gauss, X_test, y_test, \n",
        "                      title=\"Test Data & Decision Boundary\", ax=axes[1])\n",
        "\n",
        "# Mark misclassified points on test set\n",
        "y_pred = clf_gauss.predict(X_test)\n",
        "misclassified = y_pred != y_test\n",
        "if misclassified.any():\n",
        "    axes[1].scatter(X_test[misclassified, 0], X_test[misclassified, 1],\n",
        "                   facecolors='none', edgecolors='black', s=200, linewidths=2,\n",
        "                   label='Misclassified')\n",
        "    axes[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
